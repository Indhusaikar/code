{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b63b95b8-b4ed-4bc3-a5a8-2e8ccc7e4748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.chart import BarChart, Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d077df0d-f2ff-4a08-ae5f-c8320231804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the three Excel sheets\n",
    "svm_df = pd.read_excel('G:/datasets/tom_results/res_svm.xlsx', sheet_name='SVM')  # SVM results\n",
    "rf_df = pd.read_excel('G:/datasets/tom_results/res_rf.xlsx', sheet_name='RF')     # RF results\n",
    "knn_df = pd.read_excel('G:/datasets/tom_results/res_knn.xlsx', sheet_name='KNN')  # KNN results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8662bd-9600-4651-be42-e7b1f8979fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Model  Accuracy  Precision    Recall  F1 Score\n",
      "0   SVM  0.957265   0.955603  0.957265   0.95624\n",
      "           Model  Accuracy  Precision    Recall  F1 Score\n",
      "0  Random Forest  0.945869   0.941107  0.945869   0.93892\n",
      "  Model  Accuracy  Precision    Recall  F1 Score\n",
      "0   KNN  0.931624   0.927992  0.931624  0.912964\n"
     ]
    }
   ],
   "source": [
    "# Display the dataframes to ensure they are loaded correctly\n",
    "print(svm_df)\n",
    "print(rf_df)\n",
    "print(knn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17ca720f-252e-4652-888a-8da40e98986a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the results into a single DataFrame\n",
    "combined_df = pd.concat([svm_df, rf_df, knn_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f54590d6-6245-4aa7-a848-5a6fb622de4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined results to a new Excel file\n",
    "output_file = 'G:/datasets/tom_results/combined_model_results.xlsx'\n",
    "combined_df.to_excel(output_file, sheet_name='Model_Comparison', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a09f26-8440-482e-bd8d-43009565c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Excel file to insert the chart\n",
    "wb = load_workbook(output_file)\n",
    "ws = wb['Model_Comparison']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d51c3ccb-1836-42bf-9638-a353ac4ad141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data range for the chart (B2:E4 contains accuracy, precision, recall, f1 score)\n",
    "data = Reference(ws, min_col=2, min_row=1, max_col=5, max_row=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3eb04ed-3af5-47cb-a868-4a3b43e5ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the category labels (model names in A2:A4)\n",
    "categories = Reference(ws, min_col=1, min_row=2, max_row=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd83f168-7833-471b-a94e-6908e3b1a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bar chart\n",
    "chart = BarChart()\n",
    "chart.title = \"Model Comparison: Accuracy, Precision, Recall, F1 Score\"\n",
    "chart.x_axis.title = 'Metrics'\n",
    "chart.y_axis.title = 'Scores'\n",
    "chart.add_data(data, titles_from_data=True)\n",
    "chart.set_categories(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b65367d-f0ce-4889-9499-e3ed1398781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the chart to the sheet (position it in a specific cell)\n",
    "ws.add_chart(chart, \"G2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47d87a42-1685-4200-b5f9-613b3c15e7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison graph saved in G:/datasets/tom_results/comparison_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_file = 'G:/datasets/tom_results/comparison_results.xlsx'\n",
    "wb.save(output_file)\n",
    "print(f\"Comparison graph saved in {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b615523-05c9-4db8-9037-892db038b92f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
